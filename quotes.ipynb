{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp2AiyB9wayJ",
        "outputId": "1e2a4a98-eb0b-48cc-b05f-8eacedfeb1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scrapy\n",
            "  Using cached Scrapy-2.12.0-py2.py3-none-any.whl (311 kB)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from scrapy) (24.2)\n",
            "Collecting lxml>=4.6.0\n",
            "  Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "Collecting itemloaders>=1.0.1\n",
            "  Using cached itemloaders-1.3.2-py3-none-any.whl (12 kB)\n",
            "Collecting itemadapter>=0.1.0\n",
            "  Using cached itemadapter-0.10.0-py3-none-any.whl (11 kB)\n",
            "Collecting cssselect>=0.9.1\n",
            "  Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tldextract\n",
            "  Using cached tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "Collecting protego>=0.1.15\n",
            "  Using cached Protego-0.3.1-py2.py3-none-any.whl (8.5 kB)\n",
            "Collecting service-identity>=18.1.0\n",
            "  Using cached service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
            "Collecting parsel>=1.5.0\n",
            "  Using cached parsel-1.9.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting Twisted>=21.7.0\n",
            "  Using cached twisted-24.11.0-py3-none-any.whl (3.2 MB)\n",
            "Collecting zope.interface>=5.1.0\n",
            "  Using cached zope.interface-7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n",
            "Collecting PyDispatcher>=2.0.5\n",
            "  Using cached PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Collecting queuelib>=1.4.2\n",
            "  Using cached queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting cryptography>=37.0.0\n",
            "  Using cached cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "Collecting pyOpenSSL>=22.0.0\n",
            "  Using cached pyOpenSSL-24.3.0-py3-none-any.whl (56 kB)\n",
            "Collecting w3lib>=1.17.0\n",
            "  Using cached w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in ./.venv/lib/python3.10/site-packages (from scrapy) (0.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.10/site-packages (from cryptography>=37.0.0->scrapy) (1.17.1)\n",
            "Collecting jmespath>=0.9.5\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in ./.venv/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (24.3.0)\n",
            "Collecting pyasn1\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Collecting pyasn1-modules\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "Collecting automat>=24.8.0\n",
            "  Using cached Automat-24.8.1-py3-none-any.whl (42 kB)\n",
            "Collecting constantly>=15.1\n",
            "  Using cached constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Collecting incremental>=24.7.0\n",
            "  Using cached incremental-24.7.2-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.10/site-packages (from Twisted>=21.7.0->scrapy) (4.12.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from zope.interface>=5.1.0->scrapy) (59.6.0)\n",
            "Collecting filelock>=3.0.8\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from tldextract->scrapy) (3.10)\n",
            "Collecting requests-file>=1.4\n",
            "  Using cached requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: requests>=2.1.0 in ./.venv/lib/python3.10/site-packages (from tldextract->scrapy) (2.32.3)\n",
            "Requirement already satisfied: pycparser in ./.venv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy) (2.22)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
            "Requirement already satisfied: tomli in ./.venv/lib/python3.10/site-packages (from incremental>=24.7.0->Twisted>=21.7.0->scrapy) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (2024.12.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.3.0)\n",
            "Installing collected packages: PyDispatcher, w3lib, setuptools, queuelib, pyasn1, protego, lxml, jmespath, itemadapter, hyperlink, filelock, cssselect, constantly, automat, zope.interface, requests-file, pyasn1-modules, parsel, incremental, cryptography, Twisted, tldextract, service-identity, pyOpenSSL, itemloaders, scrapy\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 59.6.0\n",
            "    Uninstalling setuptools-59.6.0:\n",
            "      Successfully uninstalled setuptools-59.6.0\n",
            "Successfully installed PyDispatcher-2.0.7 Twisted-24.11.0 automat-24.8.1 constantly-23.10.4 cryptography-44.0.0 cssselect-1.2.0 filelock-3.16.1 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.10.0 itemloaders-1.3.2 jmespath-1.0.1 lxml-5.3.0 parsel-1.9.1 protego-0.3.1 pyOpenSSL-24.3.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 queuelib-1.7.0 requests-file-2.1.0 scrapy-2.12.0 service-identity-24.2.0 setuptools-75.8.0 tldextract-5.1.3 w3lib-2.2.1 zope.interface-7.2\n",
            "Collecting crochet\n",
            "  Using cached crochet-2.1.1-py3-none-any.whl (31 kB)\n",
            "Collecting wrapt\n",
            "  Using cached wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
            "Requirement already satisfied: Twisted>=16.0 in ./.venv/lib/python3.10/site-packages (from crochet) (24.11.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (24.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (4.12.2)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in ./.venv/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (21.0.0)\n",
            "Requirement already satisfied: zope-interface>=5 in ./.venv/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (7.2)\n",
            "Requirement already satisfied: constantly>=15.1 in ./.venv/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (23.10.4)\n",
            "Requirement already satisfied: incremental>=24.7.0 in ./.venv/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (24.7.2)\n",
            "Requirement already satisfied: automat>=24.8.0 in ./.venv/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (24.8.1)\n",
            "Requirement already satisfied: idna>=2.5 in ./.venv/lib/python3.10/site-packages (from hyperlink>=17.1.1->Twisted>=16.0->crochet) (3.10)\n",
            "Requirement already satisfied: tomli in ./.venv/lib/python3.10/site-packages (from incremental>=24.7.0->Twisted>=16.0->crochet) (2.2.1)\n",
            "Requirement already satisfied: setuptools>=61.0 in ./.venv/lib/python3.10/site-packages (from incremental>=24.7.0->Twisted>=16.0->crochet) (75.8.0)\n",
            "Installing collected packages: wrapt, crochet\n",
            "Successfully installed crochet-2.1.1 wrapt-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scrapy\n",
        "!pip install crochet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reset -sf\n",
        "%reset -sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-toC77H5wayL"
      },
      "outputs": [],
      "source": [
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = 'quotes'\n",
        "    allowed_domains = ['quotes.toscrape.com']\n",
        "    start_urls = ['https://quotes.toscrape.com']\n",
        "\n",
        "    async def parse(self, response):\n",
        "        page = response.css('div.quote')\n",
        "        for element in page:\n",
        "            text = element.css(\"span.text::text\").get()\n",
        "            yield { 'text': text }\n",
        "\n",
        "        next_page = response.css('li.next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            next_page = response.urljoin(next_page)\n",
        "            self.log(next_page)\n",
        "            yield scrapy.Request(next_page, callback=self.parse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%kernelspec` not found.\n"
          ]
        }
      ],
      "source": [
        "%kernelspec list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK2114BvwayM",
        "outputId": "d54fe1a7-689a-4ac4-8caf-e78595a67141"
      },
      "outputs": [
        {
          "ename": "ReactorStopped",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReactorStopped\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     process\u001b[38;5;241m.\u001b[39mcrawl(QuotesSpider)\n\u001b[1;32m     17\u001b[0m     process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mrun_spider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Área de Trabalho/ext/.venv/lib/python3.10/site-packages/crochet/_eventloop.py:412\u001b[0m, in \u001b[0;36mEventLoop.run_in_reactor.<locals>._run_in_reactor\u001b[0;34m(wrapped, _, args, kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         result\u001b[38;5;241m.\u001b[39m_connect_deferred(d)\n\u001b[1;32m    411\u001b[0m result \u001b[38;5;241m=\u001b[39m EventualResult(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reactor)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reactor\u001b[38;5;241m.\u001b[39mcallFromThread(runs_in_reactor, result, args, kwargs)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/Área de Trabalho/ext/.venv/lib/python3.10/site-packages/crochet/_util.py:12\u001b[0m, in \u001b[0;36m_synced\u001b[0;34m(method, self, args, kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Underlying synchronized wrapper.\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Área de Trabalho/ext/.venv/lib/python3.10/site-packages/crochet/_eventloop.py:66\u001b[0m, in \u001b[0;36mResultRegistry.register\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mRegister an EventualResult.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mMay be called in any thread.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopped:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReactorStopped()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results\u001b[38;5;241m.\u001b[39madd(result)\n",
            "\u001b[0;31mReactorStopped\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import crochet\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "from twisted.internet import reactor\n",
        "\n",
        "\n",
        "crochet.setup()\n",
        "\n",
        "@crochet.run_in_reactor\n",
        "def run_spider():\n",
        "    process = CrawlerProcess(\n",
        "        settings={\n",
        "            'FEEDS': {'output.json': {'format': 'json'}},\n",
        "            'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "        },\n",
        "    )\n",
        "    process.crawl(QuotesSpider)\n",
        "    process.start()\n",
        "\n",
        "run_spider()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
